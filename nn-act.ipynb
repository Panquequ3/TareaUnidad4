{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663825c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split,DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666147f",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b638923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>600</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>700</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>600</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>680</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>600</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name   Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0                Bulbasaur    Grass  Poison    318  45      49       49   \n",
       "1                  Ivysaur    Grass  Poison    405  60      62       63   \n",
       "2                 Venusaur    Grass  Poison    525  80      82       83   \n",
       "3    VenusaurMega Venusaur    Grass  Poison    625  80     100      123   \n",
       "4               Charmander     Fire     NaN    309  39      52       43   \n",
       "..                     ...      ...     ...    ...  ..     ...      ...   \n",
       "795                Diancie     Rock   Fairy    600  50     100      150   \n",
       "796    DiancieMega Diancie     Rock   Fairy    700  50     160      110   \n",
       "797    HoopaHoopa Confined  Psychic   Ghost    600  80     110       60   \n",
       "798     HoopaHoopa Unbound  Psychic    Dark    680  80     160       60   \n",
       "799              Volcanion     Fire   Water    600  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "dataset.drop(\"#\",axis=1,inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53a90d",
   "metadata": {},
   "source": [
    "### Descripción del dataset  \n",
    "En el siguiente bloque describa el dataset a utilizar. También es necesario hacer un análisis exploratorio de los datos.\n",
    "Responda como mínimo las siguientes preguntas:\n",
    "- ¿De qué trata el dataset?\n",
    "- ¿Cuáles son las clases de salida?\n",
    "- ¿Está preparado para poder ser introducido a una red neuronal?\n",
    "- ¿Cuantas carácteristicas tiene?\n",
    "- Etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b489315",
   "metadata": {},
   "source": [
    "#### Dataset: Pokemon\n",
    "Los datos que estamos viendo en este dataset son las distintas estadisticas que poseen los pokemon de 1era a 6ta generacion, mostrando su nombre y sus tipos correspondientes, ademas de especificar si este pokemon es legendario o no\n",
    "\n",
    "Las caracteristicas que posee el dataset tiene los siguientes valores:\n",
    "* **Name:** Nombre del Pokemon en cuestion\n",
    "* **Type 1:** Primer tipo del pokemon, que siempre contiene un valor (Fire, Fairy, Steel, Water, Grass, Dragon, Ice, Poison, Bug, Normal, Flying, Fighting, Ghost, Psychic, Dark, Ground, Rock y Electric)\n",
    "* **Type 2:** Tipo secundario del pokemon, que puede no tener.\n",
    "* **HP:** (Health Points) Cantidad de vida que el pokemon posee\n",
    "* **Attack:** Valor base que tienen los pokemon para el ataque fisico\n",
    "* **Defense:** Valor base de defensa que tienen los pokemon para resistir ataques fisicos\n",
    "* **Sp. Atk:** Valor base de ataque especial que tienen los pokemon para inflingir daño especial\n",
    "* **Sp. Def:** Valor base de defensa especial que tienen los pokemon para resistir ataques especiales\n",
    "* **Speed:** Valor base de un pokemon para definir cual de los pokemones se mueve primero en batalla\n",
    "* **Total:** Suma total de todas las estadisticas de un pokemon, donde normalmente los que son sobre 600 son legendarios\n",
    "* **Generation:** Generacion a la cual pertenece el pokemon, refiriendonos a los juegos que salieron el mismo año (Ej: Rojo, Azul y Amarillo salieron el mismo año y se consideran 1era generacion)\n",
    "* **Legendary:** Valor que define si el pokemon en cuestion es legendario o no (True: Legendario / False: No legendario)\n",
    "\n",
    "Dependiendo de cual sea el estudio, el valor de salida pueden ser distintas, como por ejemplo, los tipos de el pokemon con el que normalmente se le puede asociar una estadistica, como por ejemplo el tipo acero tiene principalmente tipo acero, asi mismo, si veo un pokemon con una stat mayor en la defensa, lo mas probable es que sea acero, o viendo las estadisticas totales, puedo analizar si el pokemon en cuestion es o no legendario\n",
    "\n",
    "El Dataset de por si no posee un valor que tenga 0 en alguna parte, ya que no puede existir una estadistica en 0, tampoco los nombres pueden ser vacio, el unico valor que puede llegar a existir que sea un valor no leible seria el NaN en el segundo tipo, que esto implica que el pokemon solo tiene un tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce57c9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total         0\n",
      "HP            0\n",
      "Attack        0\n",
      "Defense       0\n",
      "Sp. Atk       0\n",
      "Sp. Def       0\n",
      "Speed         0\n",
      "Generation    0\n",
      "Legendary     0\n",
      "dtype: int64\n",
      "Total           0\n",
      "HP              0\n",
      "Attack          0\n",
      "Defense         0\n",
      "Sp. Atk         0\n",
      "Sp. Def         0\n",
      "Speed           0\n",
      "Generation      0\n",
      "Legendary     735\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores nulos en otras columnas\n",
    "columnas = [\"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\", \"Generation\", \"Legendary\"]\n",
    "valores_nulos = dataset[columnas].isnull().sum()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(valores_nulos)\n",
    "\n",
    "valores_cero = dataset[columnas].eq(0).sum()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(valores_cero)\n",
    "# En legendary es normal ya que es verdadero o falso, no un valor numerico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6e7e3-8ab6-46b1-860b-75570bdca296",
   "metadata": {},
   "source": [
    "#### Analisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c142436-3b2a-4c23-880c-7c44ea48e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4afd5fe8",
   "metadata": {},
   "source": [
    "### Preparación del dataset  \n",
    "En el siguiente bloque realice la preparación del dataset. Esto incluye:\n",
    "- Paso a tensores de PyTorch\n",
    "- División del dataset en train y test\n",
    "- Carga de los datos en DataLoader\n",
    "- Otros pasos que considere necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41c2caf5-a3b5-4018-8281-ec55b467f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PREPARANDO EL DATASET \"\"\"\n",
    "# Eliminar columnas innecesarias\n",
    "dataset.drop(\"Name\", axis=1, inplace=True)\n",
    "\n",
    "# Aplicamos codificación de variables categoricas\n",
    "dataset = pd.get_dummies(dataset, columns=[\"Type 1\", \"Type 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87afd530-0471-4d72-ac49-5d63b88ce6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos y escalamos\n",
    "X = dataset.drop(\"Legendary\", axis=1)\n",
    "y = dataset[\"Legendary\"].to_numpy() # Transformamos a numpy para usar reshape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\"\"\" Dividimos el dataset \"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3) # 30% para Test, 70% para Train\n",
    "\n",
    "\"\"\" Convertimos a tensores \"\"\"\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "\"\"\" Carga de los datos e DataLoader\"\"\"\n",
    "train = TensorDataset(X_train_tensor, y_train_tensor) # Juntamos todo el dataset de entrenamiento\n",
    "train_loader = DataLoader(train, batch_size=32, shuffle=True) \n",
    "\n",
    "test  = TensorDataset(X_test_tensor, y_test_tensor) # Juntamos todo el dataset de testeo\n",
    "test_loader  = DataLoader(test, batch_size=32)\n",
    "\n",
    "# OBS: utilizamos batch_size=32 para mantener un equilibrio \n",
    "# (al ser mas o menos pequeños, es más rápido pero a la vez mantiene estabilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3e9b579-68dc-4b21-bd6a-cf411138f5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legendarios en entrenamiento: 40.0\n",
      "No legendarios: 520.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Legendarios en entrenamiento:\", y_train_tensor.sum().item())\n",
    "print(\"No legendarios:\", len(y_train_tensor) - y_train_tensor.sum().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd1b0f",
   "metadata": {},
   "source": [
    "### Implementación de la red neuronal\n",
    "En el siguiente bloque implemente la arquitectura de red neuronal que predecirá si un Pokémon es legendario o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d31605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim # contiene algoritmos de optimización como SGD o Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9aeb0630-32b6-4a60-a11d-bd68330f13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red neuronal: 2 entradas → 4 neuronas ocultas → 1 salida\n",
    "input_dim = X_train_tensor.shape[1] # 44\n",
    "hidden_dim = 88\n",
    "output_dim = 1\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_dim), # capa oculta \n",
    "    nn.ReLU(),                        # función de activación\n",
    "    nn.Linear(hidden_dim, 64),        # capa oculta\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, output_dim),        # salida con 1 neurona\n",
    "    nn.Sigmoid()                      # función de activación de salida\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "993e64c8-1154-4526-bf30-7d9c00aa0dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc89be17",
   "metadata": {},
   "source": [
    "En el siguiente bloque cree una instancia de la red neuronal y defina la función de pérdida y el optimizador. Justifique la elección de la función de pérdida y el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b6c0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Función de perdida \"\"\"\n",
    "criterion = nn.BCELoss()  # (Binary Cross-Entropy Loss)\n",
    "# Justificación: Usada para clasificación binaria, el cual es este caso (legendario - no legendario)\n",
    "\n",
    "\"\"\" Optimizador \"\"\"\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# Justificación: Pensamos que podría ser una buena opción para el dataset\n",
    "# este actualiza los parametros dando pequeños pasos en la dirección que reduce el error\n",
    "# Se decidió utilizar un learning rate (lr) pequeño para dar pasos mas estables (aunque más lentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f9db7",
   "metadata": {},
   "source": [
    "En el siguiente bloque entrene la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2678eeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0, pérdida: 0.0358\n",
      "Época 10, pérdida: 0.2035\n",
      "Época 20, pérdida: 0.0595\n",
      "Época 30, pérdida: 0.2331\n",
      "Época 40, pérdida: 0.1497\n",
      "Época 50, pérdida: 0.2341\n",
      "Época 60, pérdida: 0.0337\n",
      "Época 70, pérdida: 0.1188\n",
      "Época 80, pérdida: 0.0287\n",
      "Época 90, pérdida: 0.0281\n",
      "Época 100, pérdida: 0.1637\n",
      "Época 110, pérdida: 0.1522\n",
      "Época 120, pérdida: 0.0845\n",
      "Época 130, pérdida: 0.0964\n",
      "Época 140, pérdida: 0.0952\n",
      "Época 150, pérdida: 0.1853\n",
      "Época 160, pérdida: 0.0778\n",
      "Época 170, pérdida: 0.1681\n",
      "Época 180, pérdida: 0.2079\n",
      "Época 190, pérdida: 0.1992\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Época {epoch}, pérdida: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebffb48-083f-461b-a07f-809e0f09e9cf",
   "metadata": {},
   "source": [
    "Se realizó una prueba, para ver más o menos en cuantas epocas convergía:\n",
    "(más o menos parece ocurrir entre la epoca 120 y 200)\n",
    "```\n",
    "Época 0, pérdida: 0.3458  \n",
    "Época 10, pérdida: 0.0642  \n",
    "Época 20, pérdida: 0.0693  \n",
    "Época 30, pérdida: 0.4736  \n",
    "Época 40, pérdida: 0.1876  \n",
    "Época 50, pérdida: 0.0619  \n",
    "Época 60, pérdida: 0.1785  \n",
    "Época 70, pérdida: 0.0570  \n",
    "Época 80, pérdida: 0.0565  \n",
    "Época 90, pérdida: 0.0813  \n",
    "Época 100, pérdida: 0.1554  \n",
    "Época 110, pérdida: 0.2659  \n",
    "Época 120, pérdida: 0.0454  \n",
    "Época 130, pérdida: 0.0548  \n",
    "Época 140, pérdida: 0.2213  \n",
    "Época 150, pérdida: 0.1240  \n",
    "Época 160, pérdida: 0.0244  \n",
    "Época 170, pérdida: 0.0410  \n",
    "Época 180, pérdida: 0.1791  \n",
    "Época 190, pérdida: 0.1218  \n",
    "Época 200, pérdida: 0.1544  \n",
    "Época 210, pérdida: 0.0539  \n",
    "Época 220, pérdida: 0.0707  \n",
    "Época 230, pérdida: 0.1222  \n",
    "Época 240, pérdida: 0.1902  \n",
    "Época 250, pérdida: 0.0901  \n",
    "Época 260, pérdida: 0.2040  \n",
    "Época 270, pérdida: 0.0270  \n",
    "Época 280, pérdida: 0.1860  \n",
    "Época 290, pérdida: 0.1301  \n",
    "Época 300, pérdida: 0.1201  \n",
    "Época 310, pérdida: 0.1437  \n",
    "Época 320, pérdida: 0.0828  \n",
    "Época 330, pérdida: 0.1994  \n",
    "Época 340, pérdida: 0.1987  \n",
    "Época 350, pérdida: 0.0232  \n",
    "Época 360, pérdida: 0.3386  \n",
    "Época 370, pérdida: 0.1644  \n",
    "Época 380, pérdida: 0.1918  \n",
    "Época 390, pérdida: 0.1566  \n",
    "Época 400, pérdida: 0.0879  \n",
    "Época 410, pérdida: 0.1948  \n",
    "Época 420, pérdida: 0.2751  \n",
    "Época 430, pérdida: 0.1777  \n",
    "Época 440, pérdida: 0.0876  \n",
    "Época 450, pérdida: 0.0379  \n",
    "Época 460, pérdida: 0.0487  \n",
    "Época 470, pérdida: 0.1748  \n",
    "Época 480, pérdida: 0.0857  \n",
    "Época 490, pérdida: 0.1173  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb82e28",
   "metadata": {},
   "source": [
    "En el siguiente bloque evalue el rendimiento de la red (Métricas de evaluación, matriz de confusión, etc.) y responda las siguientes preguntas:\n",
    "- ¿Cuántas épocas fueron necesarias para converger?\n",
    "- ¿Cuál fue la precisión final?\n",
    "- ¿El entrenamiento de su red neuronal fue exitoso?\n",
    "- ¿Cuales son los ejemplos que más confunde a la red neuronal? Responda el porqué de acuerdo a su conocimiento del dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94d85944-edf4-4c81-96b5-d3b0b620b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precisión en test: 0.92\n"
     ]
    }
   ],
   "source": [
    "# probamos con test\n",
    "with torch.no_grad(): # Desactivamos el cálculo de la gradiente\n",
    "    y_test_pred = model(X_test_tensor) # Hace una predicción sobre los datos de prueba\n",
    "    y_test_pred_labels = (y_test_pred > 0.5).float() # Convierte la probabilidad en una clasificación binaria\n",
    "    acc = (y_test_pred_labels == y_test_tensor).float().mean() # Compara las predicciones con las etiquetas reales\n",
    "    print(f\"\\nPrecisión en test: {acc.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e03d1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusión:\n",
      "[[213   2]\n",
      " [ 18   7]]\n",
      "Precisión: 0.78\n",
      "Recall: 0.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# Convertimos tensores a NumPy\n",
    "y_true = y_test_tensor.numpy()\n",
    "y_pred = y_test_pred_labels.numpy()\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Precisión y recall\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(f\"Precisión: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2adcb3c3-ca0f-4f6c-9b43-a4e3fd90e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de legendarios reales: 25.0\n",
      "Cantidad de legendarios predichos: 9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de legendarios reales:\", y_test_tensor.sum().item())\n",
    "print(\"Cantidad de legendarios predichos:\", y_test_pred_labels.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c43cf5a",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "En el siguiente bloque escriba sus conclusiones sobre el trabajo realizado. Además responda las siguientes preguntas:\n",
    "- Sobre la matriz de confusión, si usted fuese un entrenador Pokémon, ¿Elegiría a Pokémon ubicados en FP o FN para su equipo? ¿Por qué?\n",
    "- Entrene un modelo de aprendizaje automático diferente al de la red neuronal (eg. RF) y compare los resultados. ¿Cuál fue el mejor modelo? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff2747",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5262747",
   "metadata": {},
   "source": [
    "## Problema 2\n",
    "\n",
    "### Representaciones internas a partir de datos sin etiquetar  \n",
    "En esta sección se trabajará con un enfoque diferente al utilizado previamente. Ahora no se utilizarán etiquetas para guiar el aprendizaje del modelo. En su lugar, el objetivo será encontrar una forma eficiente de representar cada instancia del dataset en un espacio de menor dimensión.\n",
    "\n",
    "Diseñe un modelo que reduzca la dimensionalidad de los datos, y entrene dicho modelo utilizando el conjunto completo. Luego, visualice la representación de los datos en dos dimensiones. Para el resto siga un esquema similar al del problema anterior.\n",
    "\n",
    "Responda las siguientes preguntas:\n",
    "- ¿Se observan agrupaciones o patrones en la representación obtenida?\n",
    "- ¿Es posible distinguir algún tipo de separación visual al colorear los puntos según si un Pokémon es legendario o no?\n",
    "- ¿Qué interpretación podrías darle a la distribución resultante?\n",
    "- ¿Sus resultados tienen alguna relación con el problema anterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b003d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
